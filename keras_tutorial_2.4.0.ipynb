{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "keras_tutorial_2.4.0.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "db0jfzTsts76"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bxG8wl5Tts8I"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import datetime"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BWKs_CSots8J"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import tensorflow.keras.models as models\n",
        "# We use models.Model which is the same as keras.Model\n",
        "import tensorflow.keras.layers as layers"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "X_bbY_Tvts8K",
        "outputId": "39ad5f88-1ef0-4b50-86ce-ee435291230c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(tf.__version__)\n",
        "print(keras.__version__)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.4.1\n",
            "2.4.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IQZJrAa-ts8M"
      },
      "source": [
        "### Data setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gAVR6cdSts8N",
        "outputId": "287a4859-bb4f-4646-91d2-934b32e6847b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        }
      },
      "source": [
        "# load data\n",
        "X_test = np.load(\"X_test.npy\")\n",
        "y_test = np.load(\"y_test.npy\")\n",
        "person_train_valid = np.load(\"person_train_valid.npy\")\n",
        "X_train_valid = np.load(\"X_train_valid.npy\")\n",
        "y_train_valid = np.load(\"y_train_valid.npy\")\n",
        "person_test = np.load(\"person_test.npy\")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-970799cabe38>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# load data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"X_test.npy\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"y_test.npy\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mperson_train_valid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"person_train_valid.npy\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mX_train_valid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"X_train_valid.npy\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    414\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 416\u001b[0;31m             \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menter_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos_fspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    417\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'X_test.npy'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nq9Ldvjots8O"
      },
      "source": [
        "# adjust label values\n",
        "y_train_valid -= 769\n",
        "y_test -= 769"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZEPKTK9nts8O"
      },
      "source": [
        "print ('Training/Valid data shape: {}'.format(X_train_valid.shape))\n",
        "print ('Test data shape: {}'.format(X_test.shape))\n",
        "print ('Training/Valid target shape: {}'.format(y_train_valid.shape))\n",
        "print ('Test target shape: {}'.format(y_test.shape))\n",
        "print ('Person train/valid shape: {}'.format(person_train_valid.shape))\n",
        "print ('Person test shape: {}'.format(person_test.shape))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tb0McVblts8P"
      },
      "source": [
        "# split into train and validation set. Assumes iid\n",
        "perm = np.random.permutation(X_train_valid.shape[0])\n",
        "numTrain = int(0.8*X_train_valid.shape[0])\n",
        "numVal = X_train_valid.shape[0] - numTrain\n",
        "Xtrain = X_train_valid[perm[0:numTrain]]\n",
        "ytrain = y_train_valid[perm[0:numTrain]]\n",
        "Xval = X_train_valid[perm[numTrain: ]]\n",
        "yval = y_train_valid[perm[numTrain: ]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZyiMr6LKts8Q"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mt4l5-c3ts8Q"
      },
      "source": [
        "### Fully-connected (Dense) and RNN layers. Compiling a model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zxm4_P4wts8R"
      },
      "source": [
        "hidden_dim = 20"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Qc38oe0ts8T"
      },
      "source": [
        "# Building a Sequential model:\n",
        "model = models.Sequential()\n",
        "model.add(layers.Permute((2, 1), input_shape=(22, 1000))) # (batch, 22, 1000) -> (batch, 1000, 22)\n",
        "model.add(layers.SimpleRNN(hidden_dim)) # (batch, 1000, 22) -> (batch, hidden_dim)\n",
        "                                        # Use return_sequences=True to use in cascaded RNNs\n",
        "model.add(layers.Dense(4, activation='softmax')) # (batch, hidden_dim) -> (batch, 4)\n",
        "model.compile('adam', 'sparse_categorical_crossentropy', metrics=['acc'])\\\n",
        "    # Need to compile model before running\n",
        "    # use optimizer='sgd' if desired. Seems to be case-insensitive\n",
        "    # use loss = 'categorical_crossentropy' for one-hot labels\n",
        "    # see https://www.tensorflow.org/api_docs/python/tf/keras/metrics for other metrics.\n",
        "    #     Metrics might not have string names."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GJMXN4PIts8U"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_y-0RWJRts8U"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oBrXls8Cts8V"
      },
      "source": [
        "# Equivalent functional declaration:\n",
        "inputs = layers.Input(shape=(22, 1000), name='inputs')\n",
        "    # Needed for first layer. Expects input of (batch, 22, 1000)\n",
        "    # We can also name our layers. Useful for getting a layer by a string name.\n",
        "p1 = layers.Permute((2, 1), name='p1')(inputs)\n",
        "    # Format is ClassName(*args, **kwargs)(upstream_layer)\n",
        "    # Permute: count batch dimension as 0\n",
        "rnn = layers.SimpleRNN(hidden_dim, name='rnn')(p1)\n",
        "outputs = layers.Dense(4, activation='softmax', name='outputs')(rnn)\n",
        "model = models.Model(inputs=inputs, outputs=outputs, name='functional_model') # or keras.Model(*, **)\n",
        "    # Need to declare a model specifying input and output layers.\n",
        "    # Can pass lists of layers instead.\n",
        "    # We can also name our model.\n",
        "model.compile('adam', 'sparse_categorical_crossentropy', metrics=['acc']) # Compiling is the same."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oa1OgkwAts8V"
      },
      "source": [
        "rnn_weights = model.get_layer('rnn').get_weights()\n",
        "# Dense layer: 22->20\n",
        "# Recurrent weight: 20x20, i.e. hidden_dim x hidden_dim\n",
        "# bias: 20\n",
        "for w in rnn_weights:\n",
        "    print(w.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Rjb6Zpmts8W"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D8gaU7Mnts8W"
      },
      "source": [
        "# If you want an intermediate output, compile another model:\n",
        "rnn_output = models.Model(inputs=inputs, outputs=model.get_layer('rnn').output)\n",
        "    # Can pass the object reference (e.g. inputs) or the layer output (model.get_layer('rnn').output)\n",
        "out = rnn_output(Xval)\n",
        "print(type(out), out.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pFXEZYu5ts8X"
      },
      "source": [
        "# Adding weight and activity regularizers:\n",
        "from tensorflow.keras.regularizers import L1, L2\n",
        "layers.Dense(4, activation='softmax', kernel_regularizer=L1(0.01), activity_regularizer=L2(0.01))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Izz1G0rBts8Y"
      },
      "source": [
        "# Concatenating layers\n",
        "inputs = layers.Input(shape=(22, 1000))\n",
        "d1 = layers.Dense(20, activation='relu', kernel_regularizer=L1(0.01))(inputs)\n",
        "d2 = layers.Dense(10, activation='relu', kernel_regularizer=L2(0.01), activity_regularizer=L1(0.001))(inputs)\n",
        "cat1 = layers.Concatenate()([d1, d2])\n",
        "f1 = layers.Flatten()(cat1)\n",
        "outputs = layers.Dense(4, activation='softmax')(f1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ixq_pMWxts8Y"
      },
      "source": [
        "model = models.Model(inputs=inputs, outputs=outputs)\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gtS46uG-ts8Z"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YFF0thqAts8Z"
      },
      "source": [
        "### Training a model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kaaBXwS3ts8a"
      },
      "source": [
        "# For visualization via TensorBoard\n",
        "logdir = \"logs/scalars/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "tensorboard_callback = keras.callbacks.TensorBoard(log_dir=logdir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XQ-eBzqmts8a"
      },
      "source": [
        "# See also: lr_scheduler"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WwqGBIdKts8a"
      },
      "source": [
        "loss_hist = model.fit(Xtrain, ytrain, validation_data=(Xval, yval), epochs=5, callbacks=[tensorboard_callback])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Bag3YCcts8b"
      },
      "source": [
        "# Necessary for %tensorboard ...\n",
        "%load_ext tensorboard"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SaJiuJEQts8b"
      },
      "source": [
        "# Re-run after timeout if error, or find and go to localhost:port\n",
        "%tensorboard --logdir logs/scalars --port=7000"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XrYQMKDMts8c"
      },
      "source": [
        "# To shutdown: replace $pid with the process id and run:\n",
        "# Unix:\n",
        "#!kill $pid\n",
        "# Windows:\n",
        "#!Taskkill /PID $pid /F"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gs1dXukjts8c"
      },
      "source": [
        "hist = loss_hist.history\n",
        "list(hist)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-YnHVgrLts8d"
      },
      "source": [
        "plt.figure(figsize=(15, 5))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(hist['loss'])\n",
        "plt.plot(hist['val_loss'])\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'])\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(hist['acc'])\n",
        "plt.plot(hist['val_acc'])\n",
        "plt.ylabel('acc')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kuX1lTizts8e"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E9KFHQVOts8f"
      },
      "source": [
        "## Implementing Shallow ConvNet (Schirrmeister et al. 2018)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PjzIffUbts8f"
      },
      "source": [
        "def Ksquare(x):\n",
        "    return tf.pow(x, 2)\n",
        "def Klog(x):\n",
        "    return tf.math.log(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4mPVxNMkts8g"
      },
      "source": [
        "inputs = layers.Input(shape=(22, 1000))\n",
        "r1 = layers.Reshape((22, 1000, 1))(inputs)\n",
        "    # (N, 22, 1000) -> (N, 22, 1000, 1)\n",
        "c1 = layers.Conv2D(40, (1, 25), activation='elu', data_format='channels_last')(r1)\n",
        "    # (N, 22, 1000, 1) -> (N, 22, 976, 40), i.e. NHWC -> NHWC. 'channels_last' is default\n",
        "p1 = layers.Permute((2, 1, 3))(c1)\n",
        "    # (N, 22, 976, 40) -> (N, 976, 22, 40)\n",
        "r2 = layers.Reshape((976, 22*40))(p1)\n",
        "    # (N, 976, 22, 40) -> (N, 976, 22*40)\n",
        "d1 = layers.Dense(40, activation='elu')(r2)\n",
        "    # (N, 976, 22*40) -> (N, 976, 40)\n",
        "    # weight_shape = 22*40 x 40 = 35200\n",
        "    # bias_shape = 40\n",
        "sq1 = layers.Activation(Ksquare)(d1)\n",
        "ap1 = layers.AveragePooling1D(75, strides=15)(sq1)\n",
        "    # (N, 976, 40) -> (N, 61, 40)\n",
        "log1 = layers.Activation(Klog)(ap1)\n",
        "f1 = layers.Flatten()(log1)\n",
        "    # (N, 61, 40) -> (N, 61*40)\n",
        "outputs = layers.Dense(4, activation='softmax')(f1)\n",
        "    # (N, 61*40) -> (N, 4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m9bmUUAqts8h"
      },
      "source": [
        "model = models.Model(inputs=inputs, outputs=outputs, name='shallow_convnet')\n",
        "model.compile('adam', 'sparse_categorical_crossentropy', metrics=['acc'])\n",
        "#model.compile(keras.optimizers.Adam(), keras.losses.SparseCategoricalCrossentropy(), \n",
        "#             metrics=[keras.metrics.SparseCategoricalAccuracy()])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qvhxe1SOts8i"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "u_10PXiQts8j"
      },
      "source": [
        "loss_hist = model.fit(Xtrain, ytrain, validation_data = (Xval, yval), epochs = 10, verbose=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fA-2tyYuts8k"
      },
      "source": [
        "hist = loss_hist.history\n",
        "\n",
        "plt.figure(figsize=(15, 7))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(hist['loss'])\n",
        "plt.plot(hist['val_loss'])\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'])\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(hist['acc'])\n",
        "plt.plot(hist['val_acc'])\n",
        "plt.ylabel('acc')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7NtW9HFots8l"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}